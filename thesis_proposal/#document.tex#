\documentclass[preprint]{aastex62}
% \documentclass[manuscript]{aastex62}
%%  twocolumn, manuscript, preprint, preprint, modern and RNAAS
\usepackage[utf8]{inputenc}
%\usepackage{siunitx}
%\usepackage[spanish]{babel}
%
\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
%% Tells LaTeX to search for image files in the 
%% current directory as well as in the figures/ folder.
\graphicspath{{./}{figures/}}
%% Reintroduced the \received and \accepted commands from AASTeX v5.2
%%\received{January 1, 2018}
%%\revised{January 7, 2018}
%%\accepted{\today}
\shorttitle{A LSS Void Identifier based on $\beta$-Skeleton}
\shortauthors{F. L. Gómez-Cortés}

\renewcommand{\abstractname}{RESUMEN}
\renewcommand{\figurename}{Figura}


\begin{document}

\title{A Large Scale Structure Void Identifier for Galaxy Surveys
  Based on the $\beta$-Skeleton Graph Method}

\correspondingauthor{Felipe Leonardo Gómez-Cortés}
\email{fl.gomez10@uniandes.edu.co}

\author{Felipe Leonardo Gómez-Cortés}
\affiliation{Physics Department, Universidad de Los Andes}
\collaboration{Master Student}
\collaboration{Code 201324084}

\nocollaboration


\author{Jaime E. Forero-Romero}
\affiliation{Physics Department, Universidad de Los Andes}
\collaboration{Advisor}

% Texto comentado para la versión en español.
\iffalse
\section*{Abstract}

  We are living the golden age of observational cosmology. 
  There is a consolidated standard cosmological model ($\Lambda$CDM) that explains the observed
  Large Scale Structure (LSS) of galaxies by introducing dark matter and
  dark energy as the dominant Universe components along with baryonic matter.
  Furthermore, we are able to do precise observatioanl measurements of the 
  cosmological parameters in that model. 
  Most of this success is due to computational cosmology that is now 
  an stablished tool to probe theoretical models and compare them with observations.
  The main features of the LSS can been reproduced in large cosmological N-body simulations.
  
  One of the most striking features in the LSS are voids; irregular 
  volumes on the order of tens of Mpc scales, where the matter density is below the Universe
  average density. 
  Statistics about voids such as its volume, shape and orientation also encode cosmological information.
  For this reason there is a great interest in algorithms that find and characterize voids
  both in simulations and observations.

  The objetive of this work is to develop a new void finder based
  on the $\beta$-Skeleton method.
  The $\beta$-Skeleton has been widely used on image processing,
  recognition and machine learnig applications, it has been introduced
  recently in LSS analysis. It is a fast tool identifiying LSS filamentary structure,
  and promises to be a robust tool to make cosmological tests.
  After developing the void finder we will characterize the $\beta$-skeleton voids
  in simulations and observations. We will also make prediction for the upcoming
  Dark Energy Spectroscopic Instrument about the void population that could be detected
  with that experiment.
  

  \medskip

  Keywords: Large Scale Structure, cosmology, voids, computational astrophysics

  \keywords{ Large Scale Structure, cosmology, voids, computational astrophysics}

  \fi



  \section*{Resumen}
  Estamos viviendo en la era dorada de la cosmolog\'ia observacional.
  Existe un modelo est\'andar comol\'ogico ($\Lambda$-CDM) consolidado 
  que explica las observaciones de la Estructura de Gran Escala (EGE) de galaxias mediante
  la introducci\'on de materia oscura y energ\'ia oscura como las componentes
  dominantes del Universo.
  Actualmente es posible realizar mediciones precisas de los
  par\'ametros cosmol\'ogicos de este modelo a partir de observaciones. 
  Gran parte de estos alcances se debe a la cosmolog\'ia computacional
  que es ahora una herramienta establecida para probar modelos te\'oricos y
  compararlos con las observaciones. 

  Una de las caracter\'isticas m\'as prominentes en la EGE son los vac\'ios: vol\'umenes
  irregulares de escalas del orden de decenas de Mpc, donde la densidad de materia est\'a
  por debajo de la densidad media en el Universo. El an\'alisis estad\'istico de propiedades
  de los vac\'ios, como su volumen, forma y orientaci\'on tambi\'en nos puede dar informaci\'on
  cosmol\'ogica. Por esta raz\'on existe un gran inter\'es en algoritmos que encuentren y
  caractericen vac\'ios cosmol\'ogicos tanto en simulaciones como en observaciones.

  El objetivo de este trabajo es desarrollar un nuevo buscador de vac\'ios basado en el
  m\'etodo $\beta$-Skeleton. El m\'etodo $\beta$-Skeleton ha sido ampliamente utilizado
  en procesamiento de im\'agenes y aplicaciones de \textit{machine learning},
  recientemente ha sido introducido en el an\'alisis de EGE. Esta es una herramienta r\'apida
  para identificar estructuras filamentarias en la EGE, y promete ser una herramienta robusta
  para realizar an\'alisis cosmol\'ogicos. Luego de desarrollar el buscador de vac\'ios
  caracterizaremos los vac\'ios del $\beta$-Skeleton en simulaciones y observaciones. Tambi\'en
  realizaremos predicciones para el experimento en desarrollo Dark Energy Spectroscopic
  Instrument (DESI) acerca de la poblaci\'on de vac\'ios que podr\'a detectar.

  \medskip

  Palabras clave: estructura de gran escala, cosmología, vacíos,
  astrofísica computacional.

%%  \end{abstract}

\newpage

  \section{Introducción}

  La cosmolog\'ia f\'isica actual considera al Universo como un ente
  dinámico.  
  Hay dos aspectos principales en esta evoluci\'on: la expansi\'on que
  hace que la densidad global de materia disminuye
  con el tiempo cosmol\'ogico y, el segundo, la formaci\'on de
  estructuras localmente cada vez m\'as densas debido al colapso
  gravitacional. 

  Las observaciones del fondo de radiaci\'on c\'osmica de microondas
  \citep{WMAP2013} y de la distribuci\'on de galaxias a gran escala
  \citep{SDSS-DR14-2017} apuntan a que esta evoluci\'on puede ser descrita
  por un pu\~nado de par\'ametros cosmol\'ogicos, donde los m\'as
  importantes son la densidad de materia y la densidad de energ\'ia
  oscura. 
  
  El reto de la cosmolog\'ia actual
  es aumentar la precisi\'on de las
  mediciones de estos par\'ametros cosmol\'ogicos. 
  Esto no s\'olo se logra con mediciones m\'as precisas sino con
  m\'etodos independientes para acotar los par\'ametros
  cosmol\'ogicos.
  Aunque un m\'etodo independiente pueda tener una incertidumbre
  grande, considerar las cotas impuestas por varios m\'etodos
  simult\'aneamente reduce la incertidumbre sobre los par\'ametros
  cosmol\'ogicos.

  Una de las pruebas cosmol\'ogicas que ha emergido en la \'ultima
  d\'ecada es la caracterizaci\'on de los vac\'ios cosmol\'ogicos;
  grandes regiones del espacio que cuentan con una baja densidad de
  galaxias. 


  

  \section{Estado del Arte}

Los vac\'ios cosmol\'ogicos son evidentes en mapas de la
distribuci\'on tridimensional de galaxias hechos en las \'ultimas dos
d\'ecadas \citep{SDSS-DR14-2017}.
El proyecto de mapeo más emblem\'atico de la primera década del
siglo XXI fue el \textit{Sloan Digital Sky Survey (SDSS)} el cu\'al
con el experimento BOSS ha estimado la posici\'on en el espacio de
más de 1.5 milones de galaxias de redshift $0<z<1.0$.

El trabajo de interpretaci\'on de estos mapas en t\'erminos de
par\'ametros cosmol\'ogicos requiere la realizaci\'on de simulaciones
que sigan la formaci\'on de estructuras en un Universo en expansi\'on.
Una simulación m\'as emblem\'atica en este aspecto es el \textit{Millenium Run}
hecha en el Instituto Max Planck de Astrof\'isica hace 15 a\~nos. 

La Figura \ref{fig:pie_millenium_walls} compara los mapas de la
distribuci\'on de galaxias obtenidos por simulaciones (rojo) y por
observaciones (azul).
Cada punto representa una galaxia.
En estas im\'agenes los grandes filamentos donde se aglomeran la
galaxia se complementan con las regiones donde hay menos galaxias que
conforman los vac\'ios que nos interesan en esta tesis.

  \begin{figure}
    \plotone{pie_millennium_walls}
    \caption{Distribuci\'on espacial de galaxias observada en mapeos como el SDSS y
      el 2dFRGS (en azul) comparadas con resultados de la simulación Millenium (rojo).
      Instituto de Astrofísica Max Planck. Cada punto representa una galaxia.
      La Vía Láctea se encuentra en el centro de los mapas, que cubren diferentes regiones
      del cielo en escalas distintas.
      En el segmento de la izquierda muestra la estructura a gran escala compuesta por
      filamentos donde se agrupan las galaxias y grandes vacíos donde es baja la densidad
      de galaxias, del catálogo 2dFGRS. Hacia la periferia distante solo se puedne ver las
      galaxias más brillantes, por eso la baja densidad hacia el borde.
      A la derecha vemos en un segmento del la simulación Millenium,
     En los
      segmentos superiores vemos estructuras de varias decenas de Mpc encontradas en dos
      catálogos (SDSS y 2dFGRS). En los dos segmentos inferiores, vemos estructuras con
      tamaños similares generadas por la misma simulación Millenium.
      \label{fig:pie_millenium_walls}}
  \end{figure}
  
  El \textit{Dark Energy Survey Instrument} (DESI) es uno de los catálogos de galaxias
  de la nueva generación. DESI es un experimento en etapa
  de construcción. Usa el telescopio Mayall de 4m en Kitt Peak, Californa. Tiene
  5,000 fibras montadas sobre brazos robóticos posicionadores que permiten tomar  el espectro
  de cerca de 2,000 objetos
  simultáneamente en cada exposición. La perimera fase observará el cielo por
  cinco años, tomando el espectro de más de 30 millones de galaxias.
  %Puede ser considerado una versión potenciada del SDSS (640 espectros simultáneos con las
  %fibras ubicadas manualmente, en un telescopio de $2.5 \rm~m$).

  El desarrollo de DESI involucrada varias partes: un lado el equipo de construcción
  del \textit{hardware} de posicionamiento de las fibras, construcción del espectrógrafo y
  montaje sobre el telescopio. Por otro lado está el equipo de programación de la ubicación
  de las fibras y simulación de observaciones, usan catálogos ficticios del cielo a
  partir de simulaciones cosmológicas, recrean las condiciones atmosféricas 
  de observación, para alimentan el sistema
  de análisis de datos. 
  Así se compara el desempeño del análisis de datos de DESI en el
  cielo simulado de los cat\'alogs ficticios. 

  DESI generará catálogos de galaxias nunca antes vistos 
  que permitirán realizar una gran cantidad de pruebas para acotación de parámetros cosmológicos,
  en particular densidad de materia oscura. Este parámetro puede estudiarse mediante análisis
  de vacíos de la red cósmica.


  \section{Marco Teórico}

  La EGE muestra que la mayor parte del volúmen del Universo está dominado
  por los vacíos de la red cósmica. Allí la densidad de materia es inferior al $20\%$ de la
  densidad media del universo \citep{Weygaert2014}.
  El universo inicialmente homogeneo tiene una evolución con dinámica no lineal en regiones
  con sobredensidad donde se forman estructuras  de materia ligadas gravitacionalmente
  cuyos marcadores son las galaxias (agrupadas en filamentos, paredes y nodos),
  Las regiones de baja densidad que obedecen dinámicas lineales, están más cercanas a
  las condiciones iniciales del Universo. En estas regiones de baja densidad la métrica está
  dominada por la energía oscura. Aquí yace el interés por estudiar los vacíos en la
  red cósmica para explorar parámetros cosmológicos.
  
  \citet{Aspen-Amsterdam2008} realizaron una comparación de distintos algoritmos para encontrar vacíos
  en la red cósmica. Estos pueden clasificarse en dos: Métodos que utilizan distribución de materia
  oscura y métodos que utilizan galaxias/halos.

  Los métodos que buscan vacíos en la red cósmica usando materia oscura operan directamente sobre
  resultados de simulaciones. De un \textit{snapshot} de la simulación extraen el catálogo de todas
  las partículas en la simulación. En \citet{Aspen-Amsterdam2008} se comparan algunos algoritmos
  generan un campo de densidad suavizado de materia a partir de la distribución discreta de partículas
  para identificar las regiones de  densidad inferior al $20\%$ de la densidad media del Universo
  discretizando el espacio en celdas y buscando aquellas con baja densidad, 
  otros métodos definen los vacíos como regiones del espacio encerradas por superficies
  donde la densidad de materia es constante.  Los vacíos pueden identificarse desde el espacio de
  fase como las regiones donde las partículas tienden siempre a escapar. Otros métodos usan la
  Transformada de \textit{Watershed} para identificar contornos y delimitar los vacíos desde
  generando contraste en el campo escalar de densidad y encerrando las regiones.

  La aproximación de nuestro interés busca vacíos a partir de marcadores de la sobredensidad de materia
  en el Universo, en catálogos de halos de materia oscura (de simulaciones) o
  catálogos de galaxias (directamente de \textit{surveys} experimentales como el SDSS o el 2dFGRS, o bien
  de simulaciones utilizando métodos semianalíticos para generación de galaxias).

  Un modelo sencillo busca las esféras más grandes posibles  donde no haya galaxias encerradas.
  Un modelo más avanzado diferencia galaxias de los contornos (en filamentos y paredes)
  de galaxias dentro de vacíos según número de vecinos distancia a los primeros vecinos, luego se repite
  el esquema de búsqueda de esferas las esferas huecas más grandes posibles con escasas galaxias
  internas clasificadas como no pertenecientes a los contornos. Algoritmos más avanzados
  encuentran vacíos irregulares más grandes, discretizando el espacio en celdas e identificando las celdas
  vacías a una distancia mínima de las celdas con galaxias. \citep{Aspen-Amsterdam2008}.
  \begin{figure}
    \plotone{fractional_anisotropy_voids_fig1.png}
    \caption{Una fracción de la simulación Bolshoi \citep{Multidark2013} de $250 \times 250 \times \times 1 \rm ~h^{-1}~Mpc$
      Izquierda: Análisis del campo de densidad mediante el método VWEB que analiza espacio de fase..
      Medio: Clasificación de las estructuras de la red cósmica como vacíos (blanco),
      paredes (gris claro), filamentos (gris oscuro) y nudos (negro).
      Derecha: Vacíos encontrados. Los colores representan el radio efectivo de los vacíos.
      \citep{Fang2018}. \label{fig:voids_in_simulations}}
  \end{figure}
  \subsection{Test Alcock-Paczynski}
  Al construir los mapas tridimensionales del universo se convierten los observables (posición
  angular y corrimiento al rojo) en coordenadas cartesianas en el marco de referencia comovil.
  Para hacer esta conversión es necesario conocer la métrica de nuestro Universo; cómo se
  expande el espacio en función del tiempo. El modelo cosmológico estándar $\Lambda$CDM
  describe esta rata de expansión en función de algunos parámetros como la densidad de materia
  y la densidad de energía oscura en el Universo. Estos datos se pueden obtener con precisión
  de sondas como Planck y otro tipo de experimentos (BAO por ejemplo). Si se construye un mapa
  del universo con los parámetros cosmológicos erroneos, se observarán
  distorsiones en la distribución de los objetos. Este es el principio del test de
  \citet{AlcockPaczynski1979}.

  Se puede aplicar este test AP al convertir observaciones de
  vacíos (a partir de las observaciones de galaxias como marcadores de sus límites) a coordenadas
  comóviles. Una descripción detallada de esta metodología se brinda en \citet{Hamaus2015}:

  Sea $x$ el vector que denota las coordenadas de un objeto en el espacio. La distancia comovil en la
  dirección de la línea de visión se calcula como:
  \begin{equation}
    x_{\parallel} = \int _0 ^z \frac{c}{H(z')}dz',
  \end{equation}
  donde $c$ es la velocidad de la luz y $H(z)$ describe la expansión de Hubble como función del
  corrimento al rojo $z$. Si el objeto tiene velocidad radial, esta induce un corrimiento adicional
  hacia el rojo o hacia el azul. Al tener esto en cuenta queda:
  \begin{equation}
    \tilde{x}_{\parallel} = \int _0 ^{z + \frac{v_\parallel}{c}}(1+z) \frac{c}{H(z')}dz'
    \simeq x_\parallel + \frac{v_\parallel}{H(z)}(1+z)
  \end{equation}
  En tanto el ángulo $\theta$  entre un par de objetos objetos se relaciona con la distancia comovil según
  \begin{equation}
    x_{\perp} = D_A(z)\theta
  \end{equation} 
  En una métrica de  Friedmann-Lema\^itre-Robertson-Walker de curvatura $k$, la distancia
  comovil angular viene dada por:
  \begin{equation}
    D_A(z) = \frac{c}{H_0\sqrt{-\Omega_k}} \sin \left( H_o\sqrt{-\Omega_k}
    \int_0^z \frac{1}{H(z'} dz' \right).
  \end{equation}
  Este término es bastante sensible al parámetro de curvatura
  $\Omega_k = 1 - \Omega_m - \Omega_\Lambda$, en tanto la rata de expansión de Hubble
  depende en sí misma del contenido de energía y materia en el Universo como:
  \begin{equation}
    H(z) = H_0 \sqrt{ \Omega_m(1+z)^3 + \Omega_k(1+z)^2+\Omega_\Lambda}
  \end{equation}
  De este modo se puede ver cómo es necesario asumir los valores actuales correctos de los
  parámetros cosmológicos para generar mapas tridimensionales de los objetos en el cielo. Si
  estos valores no coinciden con los parámetros
  cosmológicos reales, las distancias calculadas en la lína de visión y perpendicular a ella serán
  incorrectas. Una de las herramientas fundamentales para realizar tests AP son las funciones
  de correlación. Estas pueden ser aplicadas entre pares de galaxias-vacíos o funciones de
  autocorrelación vacío-vacío.
  
  \subsection{Análisis de elipticidad}
  
  A partir del análisis estadístico de la morfología y la dinámica de los vacíos se pueden estudiar
  los parámetros cosmológicos. Las condiciones iniciales de distribución de materia en el Universo
  se toman como el modelo analítico de Zel'dovich. 

  \citet{Park-Lee2007}
  demuestran cómo la elipticidad de los vacíos
  es sensible a los parámetros cosmológicos, como un balance entre efectos de marea producidos
  por la componente de materia del Universo y la expansion misma del Universo: las perturbaciones
  iniciales tienden a crecer esféricamente por la expansión del Universo, aquí entra el parámetro
  $\Omega_\Lambda$, en tanto las fuerzas de marea (la contribución de $\Omega_m$)tienden a deformar
  los vacíos, alejándolos de la forma esférica. Desarrollan modelos analíticos sobre la distribución
  de elipticidad para la población de vacíos según los parámetros cosmológicos.

  En \citet{Bos2012} se comparan incluso cosmologías distinas al modelo
  estándar $\Lambda$CDM. Esta referencia muestra un desarrollo completo del principio de análisis de
  la elipticidad de los vacíos en la red cósmica.

  Una vez se han definido los vacíos se calcula su tensor de inercia, donde $a \geq b \geq c$ son los
  valores propios del tensor análogos a los semiejes en un elipsoide. Se define la esfericidad en
  términos de la elipticidad $s = 1 - \epsilon = c / a$ y el achatamiento como $ p = b / a$. Con esto
  el volumen del elipsoide equivalente será $V = \frac{4}{3}\pi abc$. Se puede calcular el tensor de
  marea $T_{ij}$ del potencial gravitacional $\phi$ como:
  \begin{equation}
    T_{ij} = \frac{\partial^2 \phi}{\partial x_i \partial x_j} - \frac{1}{3} \nabla^2 \phi \delta_{ij},
  \end{equation}
  los vectores propios de este tensor serán  $\lambda_1 > \lambda_2 > \lambda_3$, cuya suma es
  $\delta_\nu = \sum \lambda_i$, y están relacionados con la esfericidad y el achatamiento según:
  \begin{equation}
    \lambda_1 = \frac{1 + (\delta_\nu -2)s^2 + p^2}{p^2 + s^2 + 1}
 \end{equation}
  y  
  \begin{equation}
    \lambda_2 = \frac{1 + (\delta_\nu -2)p^2 + s^2}{p^2 + s^2 + 1}.
  \end{equation}
  La función de densidad de probabilidad $f(s)$ para una esfericidad de los vacíos de la red dada viene dada por:
  \begin{eqnarray}
    f(1-\epsilon;z) = f(s;z, R_L) = \int_0^1 \mathcal{P}\left[ p,s|\delta = \delta_\nu;\sigma(z,R_L)\right] dp \nonumber\\
    = \int_s^1 dp \frac{3375 \sqrt{2}}{ \sqrt{10 \pi} \sigma^5(z,R_L)}
      \exp \left[ \frac{-5 \delta_\nu^2 + 15 \delta_\nu ( \lambda_1 + \lambda_2 )}{2 \sigma^2(z,R_L)} \right] 
      \exp \left[ - \frac{ 15(\lambda_1^2 + \lambda_1 \lambda_2 + \lambda_2^2)}{ 2\sigma^2(z,R_L)}\right] \\
      \times (2\lambda_1 + \lambda_2 - \delta_\nu) 
       (\lambda_1 - \lambda_2)( \lambda_1 + 2\lambda_2 - \delta_\nu) \frac{ 4 (\delta_\nu - 3)^3 p s }{ ( p^2 + s^2 + 1)^3}
  \end{eqnarray}
  $\sigma(z,R_L)$ es la fluctuación RMS del campo de materia suavizado en una escala $R_L$ a
  redshift $z$:
  \begin{equation}
    \sigma^2(z,R_L) = D^2(z) \int_o^{\infty} \frac{k^2dk}{2\pi^2}P(k) W^2(kR_l)d \ln k
  \end{equation}
  \subsection{Método $\beta$-Skeleton}
  El método $\beta$-Skeleton ha sido introducido en astrofísica recientemente por \citet{Fang2018} para
  encontrar el ``esqueleto'' de la  EGE en catálogos de simulaciones y datos observacionales.
  Ha sido usado desde hace $\sim 40$ años para analizar imágenes en búsqueda de contornos e identificación
  de objetos, tiene aplicaciones en machine learning, problemas de minimización en conexión de redes
  inalámbricas. Este método es computacionalmente económico y rápido.
  
  Depende del parámetro contínuo $\beta \geq 0$ para establecer las conexiones entre conjuntos de
  puntos en el espacio. Cuando este parámetro tiende a cero, el método calcula todas las conexiones
  entre todos los puntos de la red. Se ha encontrado que valores de este parámetro cercanos a 3
  generan las estructuras filamentales en la EGE. Valores cercanos a 10 reducen demasiado las
  conexiones y se pierde la estructura filamental (figura \ref{fig:beta_skeleton_analysis}). 

  Un análisis estadístico básico de las distancias en conexiones puede revelar información subyaciente
  en la EGE. Al tomar $\beta = 0$ esta estadística se reduce a la bien conocida función de correlación
  de dos puntos, con $\beta \sim 3$ pueden detectarse diferencias tradicionalmente no visibles entre
  simulaciones de N cuerpos (que requieren pleno poder computacional) y simulaciones que incluyen
  modelos semianalíticos para generación de catálogos MOCS que son computacionalmente más rápidos.
  \begin{figure}
    \plotone{beta_skeleton_analysis.jpg}
    \caption{Grafo encontrado por el método $\beta$-Skeleton para un conjunto de galaxias. Al aumentar el
      parámetro $\beta$ se reduce el número de conexiones permitidas para cada galaxia. Con un valor cercano
      a 3 se reproducen filamentos y vacíos de la EGE.
      \citep{Fang2018} \label{fig:beta_skeleton_analysis}}
  \end{figure}

  \subsection{Datos esperados en DESI}
  Para encontrar los vacíos esperados en DESI se utilizarán catálogos
  ficticios de galaxias brillantes
  generados en la simulación Millenium-XXL (MXXL) \citep{Smith2017}, que simula un
  volúmen 216 veces más grande que la simulaciń Millenium original. Estos
  son los mismos catálogos utilizados por el equipo de DESI para recrear el cielo que pueden
  observar y calcular la posible incompletez del survey \citep{Smith2018}.
  Estos catálogos son conos de luz que van
  desde galaxias cercanas ($\sim0$) hasta galaxias lejanas ($z\sim2.2$), con una distribución
  media alrededor de $z\sim 0.2$. Se utilizan métodos Monte Carlo para poblar los halos de materia
  oscura con galaxias con luminosidad y color distintos, basados en los resultados del SDSS y de
  GAMA. Se incluyen BAO y distorsiones de redshift de acuerdo al movimiento propio de las galaxias.
  
  \section{Objetivos}

  \subsection{Objetivo Principal}
  Desarrollar un nuevo buscador de vacíos de la red cósmica en catálogos de galaxias
  basado en el método $\beta$-Skeleton.
  
  \subsection{Objetivos Específicos}

  \begin{itemize}    
      \item Identificar y catalogar vacíos de la red cósmica en
        simulaciones y observaciones.
      \item Acotar los parámetros cosmológicos asociado a la densidad
        de materia y de energía oscura a partir del catálogo de
        vacíos de la red cósmica
    \item  Crear un cat\'alogo de vaci\'os con simulaciones del Dark
      Energy Spectroscopic Instrument.
  \end{itemize}
  
  \section{Metodología}

  La primera parte de este trabajo consiste en desarrollar el código del buscador de vacíos
  en la red cósmica. Aquí se incluye una etapa de calibración de parámetros libres del buscador
  para obtener catálogos de vacíos de la red a partir de simulaciones y observaciones.
   
  Luego se hará un análisis estadístico para determinar parámetros cosmológicos.
  Se espera encontrar estadísticamente que no hayan direcciones privilegiadas para la orientación
  de los ejes (asumiendo formas elipsoidales en los halos), funciones de correlación en distancias
  transversales y longitudinales a la línea de observación para hacer pruebas de
  \citet{AlcockPaczynski1979}. La estadística de la morfología de los halos puede ser comparada
  con modelos analíticos para revisar proporciones entre poblaciones e identificar si los
  parámetros cosmológicos con los que se han realizado los cálculos son los parámetros adecuados.
  
  Finalmente se crearemos un cat\'alogo de vac\'ios en simulaciones
  que predicen el tipo de mapa que se producir\'a con el Dark Energy
  Spectrocopic Instrument a finales del 2024. 

  \subsection{Desarrollo del código}

  El código será escrito en Python3 o C++, podrá ejecutarse en el
  cluster HPC de la facultad de ciencas de la Universidad de los Andes.
  
  Para desarrollar el código se parte de la lectura de archivos estándar de catálogos de halos
  de materia oscura o distribución de galaxias. Estos puntos se ubican en un espacio tridimensional.
  Disponemos de la librería ``NGL''\citep{ngl} (Neighborhood Graph Library)
  para calcular la estructura $\beta$-Skeleton. Esta librería es de uso libre, está escrita en C++.
  Inicialmente fue desarrollada para estudiar topología de conjuntos de datos con un número de muestra
  pequeño. Puede encontrar vecinos en los conjuntos de puntos usando distintos métodos como los
  Grafos de Gabriel y el $\beta$-Skeleton, estos métodos resultan computacionalmente más económicos
  y rápidos que otros métodos más robustos como la trianguación de Delaunay.
  
  Por definición los vacíos cósmicos son regiones con baja densidad de materia, así que se
  estudiarán regiones de un campo escalar. Para esto es conveniente dividir el espacio en
  celdas discretas. El tamaño de las celdas será el primer parámetro a calibrar en el código.
  
  Se aplica el método $\beta$-Skeleton para conectar los puntos en el espacio y trazar los
  filamentos de la red cósmica. En este punto se utilizará la librería NGL \citep{ngl}.
  El parámetro $\beta$ de este método es otro parámetro a calibrar en el código. Se puede
  utilizar como guía el resultado obtenido por \citet{Fang2018}.
  Se transforman estos puntos y filamentos en un campo de densidad de materia. Este primer
  campo escalar de materia es bastante discreto y discontínuo. Será suavizado mediante un
  kernel Gaussiano, el número de veces que sea suavizado el campo de densidad y el tamaño de
  las celdas del kernel serán parámetros a calibrar en el código.

  Una vez suavizado el campo de densidad de materia se identifican los centroides
  de los vacíos de la red. Esto se puede realizar revisando, por ejemplo, puntos intermedios
  en conexiones largas que pueden aparecer en un $\beta$-skeleton con parámetro $\beta$ bajo,
  pero no aparecen en la red obtenida con el valor de $\beta$ apropiado.

  Ya identificados los centroides de los vacíos, se utiliza un método simiar a \textit{watershed}
  para identificar las regiones de baja densidad \citep{Sutter2015}. Con este método
  se planta una semilla en los centroides, todas las semillas crecen a la misma velocidad; una
  celda vecina a la vez. Se establecen ciertas reglas, por ejemplo las regiones no crecerán en
  las regiones donde el campo escalar de densidad tenga un valor alto, o se detendrán cuando
  se encuentren con otra región en crecimiento. Otro método a probar para identificar regiones
  es la construcción de esferas dentro de los vacíos de la red. 

  \section{Cronograma}

  \begin{table}[htb]
    \centering
    \begin{tabular}{|c|cccccccccccccccc| }
      \hline
      Tareas $\backslash$ Semanas & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16  \\
      \hline
      1 & X & X & X & X & X & X &   &   &   &   &   &   &   &   &   &   \\
      2 &   &   &   &   & X & X &   &   &   &   &   &   &   &   &   &   \\
      3 &   &   &   &   &   &   & X & X &   &   &   &   &   &   &   &   \\
      4 &   &   &   &   &   &   & X & X & X &   &   &   &   &   &   &   \\
      5 &   &   &   &   &   &   &   &   & X & X &   &   &   &   &   &   \\
      6 &   &   &   &   &   &   &   &   &   &   & X & X & X &   &   &   \\
      7 &   &   &   &   &   &   &   &   &   &   &   &   &   & X & X & X \\
      8 & X & X & X & X & X & X & X &   &   &   &   &   &   &   &   &   \\
      9 &   &   &   &   &   &   & X & X & X &   &   &   &   &   &   &   \\
      10&   &   &   &   &   &   &   &   &   & X & X & X & X &   &   &   \\
      11&   &   &   &   &   &   &   &   &   &   &   &   &   & X & X & X \\
      \hline
    \end{tabular}
  \end{table}

  
  \begin{enumerate}
  \item Desarrollo del código del Buscador de Vacíos Basado en $\beta$-Skeleton.
  \item Calibración de los parámetros del código.
  \item Obtención de catálogos de vacíos de la red a partir de simulaciones.
  \item Obtención de catálogos de vacíos de la red a partir de observaciones.
  \item Comparación por análisis estadístico entre simulaciones y observaciones.
  \item Cálculo de la constante cosmológica a partir de catálogo de vacíos de la red en
    observaciones.
  \item Estimación de resultados para el experimento DESI.
  \item Escritura del Documento: Introducción y marco teórico.
  \item Escritura del Documento: Desarrollo y calibración del Código.
  \item Escritura del Documento: Análisis de catálogos de vacíos de la red cósmica. 
  \item Escritura del Documento: Estimación de posibles resultados del experimento DESI y Conclusiones.
  \end{enumerate}
  
  \section{Resultados Esperados}

  Se espera construir el código de un buscador de vacíos de la red cósmica basado en el
  método $\beta$-Skeleton. Con este código se espera generar catálogos de vacíos con
  suficiente precisión para realizar pruebas cosmológicas tipo test AP y de elipticidad
  \ref{fig:expected_results}, \citep{Bos2012,Lavaux-Wandelt2009,Park-Lee2007},
  realizar pruebas con catálogos de galaxias de simulaciones y observaciones, y finalmente
  estimar la población de vacíos que encontrará el proyecto DESI.

  \begin{figure}
    \plotone{lavaux_wandelt-2010_ellipticity_prob_dens_function.png}
    \caption{ Función de densidad de probabilidad de la elipticidad de los vacíos típica
      encontrada por \citep{Lavaux-Wandelt2009} evaluada en una cosmología específica.
      \label{fig:expected_results}}
  \end{figure}

  \nocite{*}

  \begin{thebibliography}{}

  \bibitem[Alcock-Paczynski(1979)]{AlcockPaczynski1979} Alcock, C. \& Paczy\'nski, B.\ 1979, \nat, 281, 358    
    \bibitem[Colberg et al.(2008)]{Aspen-Amsterdam2008} Colbert, J. M. et al. \ 2008, \mnras, 387, 933. % Comparison of multiple void finders 2008

    \bibitem[Bos et al.(2012)]{Bos2012} Bos, P. et al. \ 2012, \mnras, 426, 440 % Testing cosmologies using void ellipticity
    \bibitem[Correa \& Lindstrom(2012)]{ngl} Correa, Carlos \& Lindstrom, Peter.\ 2011,  IEEE TVCG\ 17,12 (Dec 2011), 1852-1861
    \bibitem[El-Ad \& Piran(1997)]{El-Ad1997} El-Ad, H. \& Piran, T. \ 1997, \apj, 491, 2, 421
    \bibitem[Fang et al.(2018)]{Fang2018} Fang, F.; Forero-Romero, J.; Rossi, G.; Li, X. \& Feng, L\ 2018, arXiv, 1809.00438 astro-ph % Beta-Skeleton analysis of the Cosmic Web
    \bibitem[Hamaus et al.(2015)]{Hamaus2015} Hamaus, N.; Sutter, P.M.; Lavaux, G. \& Wandelt, B. D. \ 2015, \jcap, 11, 036    
    \bibitem[Lavaux \& Wandelt(2009)]{Lavaux-Wandelt2009} Lavaux, G. \& Wandelt, B. D. \ 2009, \mnras, 403, 1392
    \bibitem[Leclercq et al.(2015)]{2015JCAP...03..047L} Leclercq, F.; Jasche, J. et al.\ 2015, \jcap, 03, 047
    \bibitem[Park \& Lee(2007)]{Park-Lee2007} Park, D. \& Lee, J. \ 2007, \prl 98, 1301 % Void Ellipticity as a probe of Cosmology
    \bibitem[Press \& Schechter(1974)]{Press&Schechter1974} Press, W. H. \& Schechter, P. \ 1974, \apj, 187, 425-438
    \bibitem[Riebe et al.(2013)]{Multidark2013} Riebe, K. et al \ 2013, Astronomical Notes, 334, 691 % Bolshoi Simulation      
    \bibitem[Schneider(2014)]{Schneider2014} Schneider, P. \ 2014, ``Extragalactic Astronomy and Cosmology'', Springer
    \bibitem[Smith et al.(2017)]{Smith2017} Smith, A. et al. \ 2017, \mnras, 470, 4646 % Lightcone Millenium MXXL
    \bibitem[Smith et al.(2018)]{Smith2018} Smith, A. et al. \ 2018, arXiv, 1809.07355 astro-ph % Fibre assignament incompleteness in DESI
    \bibitem[Springel et al.(2005)]{Springel2005} Springel, V. et al. \ 2005, \nat, 435, 639 % Millenium Simulation
    \bibitem[Sutter et al.(2015)]{Sutter2015} Sutter, P. M.; Lavaux G.; Hamaus, N; et al. \ 2015, A\&C, 9, 1-9 % Void Finder VIDE
    \bibitem[van de Weygaert(2014)]{Weygaert2014} van de Weygaert, Rien\ 2014, Proceedings of the IAU, 308, 493 % Review of Voids

    \bibitem[SDSS Collaboration(2017)]{SDSS-DR14-2017} SDSS Collaboration \ 2017, arxiv, 1707.09322 astro-ph % SDSS Data Release 14, 2017
    \bibitem[Hinshaw et al.(2013)]{WMAP2013} Hinshaw, G. et al. \ 2013, \apjs, 208, 20. % WMAP last release
  \end{thebibliography}                                                           
                       

%\listofchanges

\end{document}
% \citet{https://arxiv.org/pdf/astro-ph/0610520.pdf} Bayes for SDSS EGE reconstruction

% \bibitem[Aarseth(2003)]{Aarseth2003} Aarseth, S. J. \ 2003, ``Gravitational N-Body Simulations'', Cambridge University Press. % Book
% \bibitem[Longair(2004)]{Longair2004} Longair, M. S. \ 2004, ``A Brief History of Cosmology'', ``Measuring and Modeling the Universe'', Carnegie Observatories Astrophysics Series, Vol 2. % BOOK
